{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Modeling\" data-toc-modified-id=\"Modeling-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Modeling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Import-Libraries\" data-toc-modified-id=\"Import-Libraries-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Import Libraries</a></span></li><li><span><a href=\"#Define-constants\" data-toc-modified-id=\"Define-constants-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Define constants</a></span></li><li><span><a href=\"#Read-in-data\" data-toc-modified-id=\"Read-in-data-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Read in data</a></span></li><li><span><a href=\"#Preprocessing\" data-toc-modified-id=\"Preprocessing-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Preprocessing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Pattern-submodel-to-handle-missing-values\" data-toc-modified-id=\"Pattern-submodel-to-handle-missing-values-1.4.1\"><span class=\"toc-item-num\">1.4.1&nbsp;&nbsp;</span>Pattern submodel to handle missing values</a></span></li></ul></li><li><span><a href=\"#Define-function-do-everything\" data-toc-modified-id=\"Define-function-do-everything-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Define function do everything</a></span></li><li><span><a href=\"#Model-preparation\" data-toc-modified-id=\"Model-preparation-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Model preparation</a></span></li><li><span><a href=\"#Train,-test-split\" data-toc-modified-id=\"Train,-test-split-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>Train, test split</a></span></li><li><span><a href=\"#Modeling\" data-toc-modified-id=\"Modeling-1.8\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span>Modeling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Evaluation-metric\" data-toc-modified-id=\"Evaluation-metric-1.8.1\"><span class=\"toc-item-num\">1.8.1&nbsp;&nbsp;</span>Evaluation metric</a></span></li><li><span><a href=\"#Baseline-model\" data-toc-modified-id=\"Baseline-model-1.8.2\"><span class=\"toc-item-num\">1.8.2&nbsp;&nbsp;</span>Baseline model</a></span></li><li><span><a href=\"#Linear-Regression\" data-toc-modified-id=\"Linear-Regression-1.8.3\"><span class=\"toc-item-num\">1.8.3&nbsp;&nbsp;</span>Linear Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Ridge-Regularzation\" data-toc-modified-id=\"Ridge-Regularzation-1.8.3.1\"><span class=\"toc-item-num\">1.8.3.1&nbsp;&nbsp;</span>Ridge Regularzation</a></span></li><li><span><a href=\"#Lasso-Regularzation\" data-toc-modified-id=\"Lasso-Regularzation-1.8.3.2\"><span class=\"toc-item-num\">1.8.3.2&nbsp;&nbsp;</span>Lasso Regularzation</a></span></li><li><span><a href=\"#Linear-Regression-+-PCA\" data-toc-modified-id=\"Linear-Regression-+-PCA-1.8.3.3\"><span class=\"toc-item-num\">1.8.3.3&nbsp;&nbsp;</span>Linear Regression + PCA</a></span></li></ul></li><li><span><a href=\"#KNN\" data-toc-modified-id=\"KNN-1.8.4\"><span class=\"toc-item-num\">1.8.4&nbsp;&nbsp;</span>KNN</a></span></li><li><span><a href=\"#Tree-Based-Models\" data-toc-modified-id=\"Tree-Based-Models-1.8.5\"><span class=\"toc-item-num\">1.8.5&nbsp;&nbsp;</span>Tree Based Models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Cart\" data-toc-modified-id=\"Cart-1.8.5.1\"><span class=\"toc-item-num\">1.8.5.1&nbsp;&nbsp;</span>Cart</a></span></li><li><span><a href=\"#Bagged-Tree\" data-toc-modified-id=\"Bagged-Tree-1.8.5.2\"><span class=\"toc-item-num\">1.8.5.2&nbsp;&nbsp;</span>Bagged Tree</a></span></li><li><span><a href=\"#Random-Forest\" data-toc-modified-id=\"Random-Forest-1.8.5.3\"><span class=\"toc-item-num\">1.8.5.3&nbsp;&nbsp;</span>Random Forest</a></span></li><li><span><a href=\"#Random-Forest--+-PCA\" data-toc-modified-id=\"Random-Forest--+-PCA-1.8.5.4\"><span class=\"toc-item-num\">1.8.5.4&nbsp;&nbsp;</span>Random Forest  + PCA</a></span></li><li><span><a href=\"#Extra-Trees\" data-toc-modified-id=\"Extra-Trees-1.8.5.5\"><span class=\"toc-item-num\">1.8.5.5&nbsp;&nbsp;</span>Extra Trees</a></span></li><li><span><a href=\"#Ada-Boost\" data-toc-modified-id=\"Ada-Boost-1.8.5.6\"><span class=\"toc-item-num\">1.8.5.6&nbsp;&nbsp;</span>Ada Boost</a></span></li></ul></li><li><span><a href=\"#SVR\" data-toc-modified-id=\"SVR-1.8.6\"><span class=\"toc-item-num\">1.8.6&nbsp;&nbsp;</span>SVR</a></span></li><li><span><a href=\"#Polynomial-Regression\" data-toc-modified-id=\"Polynomial-Regression-1.8.7\"><span class=\"toc-item-num\">1.8.7&nbsp;&nbsp;</span>Polynomial Regression</a></span></li><li><span><a href=\"#Stochastic-Gradient-Descent\" data-toc-modified-id=\"Stochastic-Gradient-Descent-1.8.8\"><span class=\"toc-item-num\">1.8.8&nbsp;&nbsp;</span>Stochastic Gradient Descent</a></span></li></ul></li><li><span><a href=\"#Model-Selection\" data-toc-modified-id=\"Model-Selection-1.9\"><span class=\"toc-item-num\">1.9&nbsp;&nbsp;</span>Model Selection</a></span></li><li><span><a href=\"#Model-Elevation\" data-toc-modified-id=\"Model-Elevation-1.10\"><span class=\"toc-item-num\">1.10&nbsp;&nbsp;</span>Model Elevation</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, SGDRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.externals.six import StringIO\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "import pydotplus\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 20200304"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCATION = 'ny_state'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: EXPLAIN YOURSELF\n",
    "TARGET = 'log_home_price_to_income_ratios'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV = 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'../data/final_{LOCATION}_agg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zipcode</th>\n",
       "      <th>total_accounting</th>\n",
       "      <th>total_airport</th>\n",
       "      <th>total_amusement_park</th>\n",
       "      <th>total_art_gallery</th>\n",
       "      <th>total_atm</th>\n",
       "      <th>total_bakery</th>\n",
       "      <th>total_bank</th>\n",
       "      <th>total_bar</th>\n",
       "      <th>total_beauty_salon</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_price_level</th>\n",
       "      <th>mean_rating</th>\n",
       "      <th>mean_user_ratings_total</th>\n",
       "      <th>population</th>\n",
       "      <th>population_density_square_miles</th>\n",
       "      <th>housing_units</th>\n",
       "      <th>price_level*rating</th>\n",
       "      <th>user_ratings_total_per_capita</th>\n",
       "      <th>rating*population_density</th>\n",
       "      <th>log_home_price_to_income_ratios</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>14741</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>410.000000</td>\n",
       "      <td>1809</td>\n",
       "      <td>29.4</td>\n",
       "      <td>1260</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>0.226645</td>\n",
       "      <td>129.36000</td>\n",
       "      <td>0.663932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>13084</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>3.232143</td>\n",
       "      <td>81.928571</td>\n",
       "      <td>3734</td>\n",
       "      <td>86.8</td>\n",
       "      <td>1601</td>\n",
       "      <td>3.693878</td>\n",
       "      <td>0.021941</td>\n",
       "      <td>280.55000</td>\n",
       "      <td>0.852157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>13159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>4.112500</td>\n",
       "      <td>108.875000</td>\n",
       "      <td>5348</td>\n",
       "      <td>68.5</td>\n",
       "      <td>2303</td>\n",
       "      <td>5.483333</td>\n",
       "      <td>0.020358</td>\n",
       "      <td>281.70625</td>\n",
       "      <td>0.866606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>14476</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>132.285714</td>\n",
       "      <td>2274</td>\n",
       "      <td>91.7</td>\n",
       "      <td>1049</td>\n",
       "      <td>7.380952</td>\n",
       "      <td>0.058173</td>\n",
       "      <td>406.10000</td>\n",
       "      <td>0.745526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>12174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>316</td>\n",
       "      <td>274.9</td>\n",
       "      <td>139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.692566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   zipcode  total_accounting  total_airport  total_amusement_park  \\\n",
       "0    14741                 0              0                     0   \n",
       "1    13084                 0              0                     0   \n",
       "2    13159                 0              0                     0   \n",
       "3    14476                 0              0                     0   \n",
       "4    12174                 0              0                     0   \n",
       "\n",
       "   total_art_gallery  total_atm  total_bakery  total_bank  total_bar  \\\n",
       "0                  0          0             0           0          0   \n",
       "1                  0          1             1           0          4   \n",
       "2                  1          1             0           0          3   \n",
       "3                  0          0             0           0          0   \n",
       "4                  0          0             0           0          0   \n",
       "\n",
       "   total_beauty_salon  ...  mean_price_level  mean_rating  \\\n",
       "0                   0  ...          1.000000     4.400000   \n",
       "1                   0  ...          1.142857     3.232143   \n",
       "2                   0  ...          1.333333     4.112500   \n",
       "3                   0  ...          1.666667     4.428571   \n",
       "4                   0  ...               NaN     0.000000   \n",
       "\n",
       "   mean_user_ratings_total  population  population_density_square_miles  \\\n",
       "0               410.000000        1809                             29.4   \n",
       "1                81.928571        3734                             86.8   \n",
       "2               108.875000        5348                             68.5   \n",
       "3               132.285714        2274                             91.7   \n",
       "4                 0.000000         316                            274.9   \n",
       "\n",
       "   housing_units  price_level*rating  user_ratings_total_per_capita  \\\n",
       "0           1260            4.400000                       0.226645   \n",
       "1           1601            3.693878                       0.021941   \n",
       "2           2303            5.483333                       0.020358   \n",
       "3           1049            7.380952                       0.058173   \n",
       "4            139                 NaN                       0.000000   \n",
       "\n",
       "   rating*population_density  log_home_price_to_income_ratios  \n",
       "0                  129.36000                         0.663932  \n",
       "1                  280.55000                         0.852157  \n",
       "2                  281.70625                         0.866606  \n",
       "3                  406.10000                         0.745526  \n",
       "4                    0.00000                         0.692566  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1521, 105)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_corr_w_dependent_variable(df, dependent_variable, corr_value):\n",
    "    '''\n",
    "    Takes df, dependent variable, and value of correlation \n",
    "    Returns a df of independant varibles that are highly (e.g. abs(corr) > 0.4) with dependent varible\n",
    "    '''\n",
    "    temp_df = df.corr()[[dependent_variable]].sort_values(by=dependent_variable, ascending=False)\n",
    "    mask_1 = abs(temp_df[dependent_variable]) > corr_value\n",
    "    return temp_df.loc[mask_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_home_price_to_income_ratios</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>log_home_price_to_income_ratios</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_open_now_True</td>\n",
       "      <td>0.613297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>population_density_square_miles</td>\n",
       "      <td>0.588593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rating*population_density</td>\n",
       "      <td>0.585944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>population</td>\n",
       "      <td>0.568489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>housing_units</td>\n",
       "      <td>0.564353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_meal_delivery</td>\n",
       "      <td>0.492924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_store</td>\n",
       "      <td>0.490759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_food</td>\n",
       "      <td>0.489080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_cafe</td>\n",
       "      <td>0.487195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_restaurant</td>\n",
       "      <td>0.471756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_bakery</td>\n",
       "      <td>0.423306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_clothing_store</td>\n",
       "      <td>0.394660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_liquor_store</td>\n",
       "      <td>0.392000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_health</td>\n",
       "      <td>0.385198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean_price_level</td>\n",
       "      <td>0.379605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_drugstore</td>\n",
       "      <td>0.367369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_bar</td>\n",
       "      <td>0.340822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_electronics_store</td>\n",
       "      <td>0.335376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>price_level*rating</td>\n",
       "      <td>0.332161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_furniture_store</td>\n",
       "      <td>0.265175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_shoe_store</td>\n",
       "      <td>0.264888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_convenience_store</td>\n",
       "      <td>0.254799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_hardware_store</td>\n",
       "      <td>0.248891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_home_goods_store</td>\n",
       "      <td>0.245025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_grocery_or_supermarket</td>\n",
       "      <td>0.239093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean_user_ratings_total</td>\n",
       "      <td>0.230804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_open_now_False</td>\n",
       "      <td>0.226203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_night_club</td>\n",
       "      <td>0.225957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_florist</td>\n",
       "      <td>0.216900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_locksmith</td>\n",
       "      <td>0.215888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_pharmacy</td>\n",
       "      <td>0.209430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_jewelry_store</td>\n",
       "      <td>0.206984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_department_store</td>\n",
       "      <td>0.148166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_bicycle_store</td>\n",
       "      <td>0.133912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_supermarket</td>\n",
       "      <td>0.133301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_hair_care</td>\n",
       "      <td>0.129904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_meal_takeaway</td>\n",
       "      <td>0.126371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_book_store</td>\n",
       "      <td>0.120127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_shopping_mall</td>\n",
       "      <td>0.106542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_open_now_nan</td>\n",
       "      <td>0.101966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_pet_store</td>\n",
       "      <td>0.095637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_art_gallery</td>\n",
       "      <td>0.095412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_general_contractor</td>\n",
       "      <td>0.086207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_beauty_salon</td>\n",
       "      <td>0.081488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_spa</td>\n",
       "      <td>0.066232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_veterinary_care</td>\n",
       "      <td>-0.060056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_atm</td>\n",
       "      <td>-0.131888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total_gas_station</td>\n",
       "      <td>-0.205987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>zipcode</td>\n",
       "      <td>-0.710616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 log_home_price_to_income_ratios\n",
       "log_home_price_to_income_ratios                         1.000000\n",
       "total_open_now_True                                     0.613297\n",
       "population_density_square_miles                         0.588593\n",
       "rating*population_density                               0.585944\n",
       "population                                              0.568489\n",
       "housing_units                                           0.564353\n",
       "total_meal_delivery                                     0.492924\n",
       "total_store                                             0.490759\n",
       "total_food                                              0.489080\n",
       "total_cafe                                              0.487195\n",
       "total_restaurant                                        0.471756\n",
       "total_bakery                                            0.423306\n",
       "total_clothing_store                                    0.394660\n",
       "total_liquor_store                                      0.392000\n",
       "total_health                                            0.385198\n",
       "mean_price_level                                        0.379605\n",
       "total_drugstore                                         0.367369\n",
       "total_bar                                               0.340822\n",
       "total_electronics_store                                 0.335376\n",
       "price_level*rating                                      0.332161\n",
       "total_furniture_store                                   0.265175\n",
       "total_shoe_store                                        0.264888\n",
       "total_convenience_store                                 0.254799\n",
       "total_hardware_store                                    0.248891\n",
       "total_home_goods_store                                  0.245025\n",
       "total_grocery_or_supermarket                            0.239093\n",
       "mean_user_ratings_total                                 0.230804\n",
       "total_open_now_False                                    0.226203\n",
       "total_night_club                                        0.225957\n",
       "total_florist                                           0.216900\n",
       "total_locksmith                                         0.215888\n",
       "total_pharmacy                                          0.209430\n",
       "total_jewelry_store                                     0.206984\n",
       "total_department_store                                  0.148166\n",
       "total_bicycle_store                                     0.133912\n",
       "total_supermarket                                       0.133301\n",
       "total_hair_care                                         0.129904\n",
       "total_meal_takeaway                                     0.126371\n",
       "total_book_store                                        0.120127\n",
       "total_shopping_mall                                     0.106542\n",
       "total_open_now_nan                                      0.101966\n",
       "total_pet_store                                         0.095637\n",
       "total_art_gallery                                       0.095412\n",
       "total_general_contractor                                0.086207\n",
       "total_beauty_salon                                      0.081488\n",
       "total_spa                                               0.066232\n",
       "total_veterinary_care                                  -0.060056\n",
       "total_atm                                              -0.131888\n",
       "total_gas_station                                      -0.205987\n",
       "zipcode                                                -0.710616"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_corr_w_dependent_variable(df, 'log_home_price_to_income_ratios', 0.06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[high_corr_w_dependent_variable(df, 'log_home_price_to_income_ratios', 0.06).index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='zipcode', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern submodel to handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a funciton to view the total and percentage of missing values \n",
    "def view_col_with_nans(df):\n",
    "    mask_percent = df.isnull().mean().sort_values(ascending=False) \n",
    "    mask_total = df.isnull().sum().sort_values(ascending=False)\n",
    "    total = mask_total[mask_total > 0]\n",
    "    percent = mask_percent[mask_percent > 0] \n",
    "    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "    return missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>price_level*rating</td>\n",
       "      <td>157</td>\n",
       "      <td>0.103222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean_price_level</td>\n",
       "      <td>157</td>\n",
       "      <td>0.103222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Total   Percent\n",
       "price_level*rating    157  0.103222\n",
       "mean_price_level      157  0.103222"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_col_with_nans(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pattern_split(df):\n",
    "    pat_1_indexes = df[pd.isnull(df).any(axis=1)].index\n",
    "    pat_0_indexes = set(df.index) - set(pat_1_indexes)\n",
    "\n",
    "    # Dataset with ALL columns\n",
    "    df_0 = df.loc[pat_0_indexes]\n",
    "    \n",
    "    # Drop columns containing NaNs\n",
    "    df_1 = df.loc[pat_1_indexes].dropna(axis=1)\n",
    "    return df_0, df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0, df_1 = pattern_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(df_0.isnull().sum().sum() == 0)\n",
    "assert(df_1.isnull().sum().sum() == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define function do everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a funciton to display train, test, cross val R2 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatWalk:\n",
    "    \"\"\"\n",
    "    If you know what I mean...\n",
    "    If you don't know what I mean: https://www.youtube.com/watch?v=P5mtclwloEQ\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        # {'model_foo': (True, model_foo),\n",
    "        #  'model_bar': (False, model_bar)\n",
    "        # }\n",
    "        self._fitted_models = {} # type: Dict['name', (bool, Model)]\n",
    "        self.X = df.drop(columns=TARGET)\n",
    "        self.y = df[TARGET] \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            self.X, \n",
    "            self.y, \n",
    "            random_state=RANDOM_STATE, \n",
    "            train_size=0.60\n",
    "        )\n",
    "    \n",
    "    def _save_model(self, name, model, is_grid_search=False):\n",
    "        self._fitted_models[name] = (is_grid_search, model)\n",
    "        \n",
    "    def fit_model(self, name, fitter):\n",
    "        model = fitter.fit(self.X_train, self.y_train)\n",
    "        self._save_model(model)\n",
    "        return self\n",
    "        \n",
    "    def fit_grid_search(self, name, pipe=None, params=None):\n",
    "        pipe = Pipeline(steps=[]) if pipe is None else pipe\n",
    "        params = {} if params is None else params\n",
    "        \n",
    "        model = GridSearchCV(\n",
    "            pipe, \n",
    "            params, \n",
    "            cv=CV\n",
    "        ).fit(self.X_train, self.y_train)\n",
    "        \n",
    "        self._save_model(name, model, is_grid_search=True)\n",
    "        return self\n",
    "    \n",
    "    def print_results(self, name):\n",
    "        grid_search, model = self._fitted_models[name]\n",
    "        if not grid_search:\n",
    "            print(f'train score: {model.score(self.X_train, self.y_train)}')\n",
    "            print(f'test score: {model.score(self.X_test, self.y_test)}')\n",
    "            print(f'cv score: {cross_val_score(model, self.X, self.y, scoring=\"r2\", cv=CV).mean()}')\n",
    "        else: \n",
    "            print(f'best params: {model.best_params_}')\n",
    "            print(f'train score: {model.score(self.X_train, self.y_train)}')\n",
    "            print(f'test score: {model.score(self.X_test, self.y_test)}')\n",
    "            print(f'cv score: {cross_val_score(model.best_estimator_, self.X, self.y, scoring=\"r2\", cv=CV).mean()}')      \n",
    "\n",
    "    def do_the_little_turn(self, name, pipe, params):\n",
    "        self.fit_grid_search(name, pipe, params)\n",
    "        self.print_results(name)\n",
    "        return self\n",
    "                  \n",
    "    def model_name_list(self):\n",
    "        return list(self._fitted_models.keys())\n",
    "                  \n",
    "    def get_model(self, name):\n",
    "        return self._fitted_models[name][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeler_0 = CatWalk(df_0)\n",
    "modeler_1 = CatWalk(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "        ('ss', StandardScaler()),\n",
    "        ('knn', KNeighborsRegressor())\n",
    "    ])\n",
    "\n",
    "params = {\n",
    "        'knn__n_neighbors': [5, 10, 50],\n",
    "        'knn__p' : [1, 2],\n",
    "        'knn__weights' : ['uniform', 'distance'],\n",
    "         #'knn__leaf_size' : [30, 40]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'knn__n_neighbors': 10, 'knn__p': 1, 'knn__weights': 'distance'}\n",
      "train score: 1.0\n",
      "test score: 0.5276977986303809\n",
      "cv score: 0.553031988319459\n",
      "best params: {'knn__n_neighbors': 50, 'knn__p': 2, 'knn__weights': 'distance'}\n",
      "train score: 0.9999999999999769\n",
      "test score: -0.047649220057391695\n",
      "cv score: 0.03167389238157925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.CatWalk at 0x12b1f03d0>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeler_0.do_the_little_turn('gs_knn', pipe, params)\n",
    "modeler_1.do_the_little_turn('gs_knn', pipe, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs_knn']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeler_0.model_name_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_once_again = modeler_0.get_model('gs_knn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_once_again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'log_home_price_to_income_ratios'\n",
    "X = df.drop(columns=target)\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=RANDOM_STATE, train_size=0.60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Evaluation metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use R2 as the model evaluation metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to plot feature importance for tree based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(model, X=X):\n",
    "    # Get feature importance, and create a pd dataframe\n",
    "    feature_importance = pd.DataFrame(dict(zip(X.columns, \n",
    "                                               gs_tree.best_estimator_['tree'].feature_importances_)).items())\n",
    "    # Sorted by feature importance\n",
    "    feature_importance = feature_importance.sort_values(by=[1])\n",
    "    \n",
    "    # Create plot\n",
    "    plt.figure(figsize=(10, 15))\n",
    "    ax = plt.barh(y = feature_importance[0], width=feature_importance[1])\n",
    "    return ax "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dummy regressor that will just predict means\n",
    "dummy_mean = DummyRegressor(strategy='mean').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_results(dummy_mean, grid_search=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(lr, grid_search=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performs okay comparing to the baseline model, and shows no apparent signs of overfitting.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: If the model shows any signs of overfitting, I will go through the following subsections using regularization for dimensionality reduction: Ridge, Lasso, and PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge Regularzation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe = Pipeline(steps=[\n",
    "#     ('sc', StandardScaler()),\n",
    "#     ('ridge', Ridge())\n",
    "# ])\n",
    "\n",
    "# params = {\n",
    "#    'ridge__alpha' : [0.01, 1, 10, 100, 200, 400],\n",
    "# }\n",
    "\n",
    "# gs_ridge = GridSearchCV(\n",
    "#     pipe,\n",
    "#     params,\n",
    "#     cv=4\n",
    "# ).fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print_results(gs_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso Regularzation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pipe = Pipeline(steps=[\n",
    "#     ('sc', StandardScaler()),\n",
    "#     ('lasso', Lasso())\n",
    "# ])\n",
    "\n",
    "# params = {\n",
    "#    'lasso__alpha' : [0.01, 0.02, 1, 2, 3, 10],\n",
    "# }\n",
    "\n",
    "# gs_lasso = GridSearchCV(\n",
    "#     pipe,\n",
    "#     params,\n",
    "#     cv=4\n",
    "# ).fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print_results(gs_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression + PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use a pipeline to combine StandardScaler and KNN\n",
    "# pipe = Pipeline(steps=[\n",
    "#     ('ss', StandardScaler()),\n",
    "#     ('pca', PCA()),\n",
    "#     ('lr_pca', LinearRegression())\n",
    "# ])\n",
    "\n",
    "# params = {\n",
    "#     'pca__n_components': [10, 15, 20],\n",
    "# }\n",
    "\n",
    "# lr_pca = GridSearchCV(\n",
    "#     pipe,\n",
    "#     params,\n",
    "#     cv=4\n",
    "# ).fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print_results(lr_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('ss', StandardScaler()),\n",
    "    ('knn', KNeighborsRegressor())\n",
    "])\n",
    "\n",
    "pipe_params = {\n",
    "    'knn__n_neighbors': [5, 10, 50],\n",
    "    'knn__p' : [1, 2],\n",
    "    'knn__weights' : ['uniform', 'distance'],\n",
    "     #'knn__leaf_size' : [30, 40]\n",
    "}\n",
    "\n",
    "gs_knn = GridSearchCV(\n",
    "    pipe,\n",
    "    pipe_params,\n",
    "    cv=4\n",
    ").fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(gs_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Based Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('ss', StandardScaler()),\n",
    "    ('tree', DecisionTreeRegressor(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'tree__max_depth' : [10, 15, 20, 30],\n",
    "    'tree__min_samples_leaf' : [2, 3, 5],\n",
    "    'tree__max_features' : [4, 6, 10]\n",
    "}\n",
    "\n",
    "gs_tree = GridSearchCV(\n",
    "    pipe,\n",
    "    params,\n",
    "    cv=4\n",
    ").fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(gs_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tree model is very overfit and has high variance, since the train score is much higher than the test score, which is common in CART models. I will use a bootstrapped tree to reduce the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagged Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('ss', StandardScaler()),\n",
    "    ('bag', BaggingRegressor(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'bag__n_estimators' : [8, 10, 12, 14],\n",
    "    'bag__max_samples' : [0.5, 0.7, 1],\n",
    "    'bag__max_features' : [0.5, 0.7, 1]\n",
    "}\n",
    "\n",
    "gs_bag = GridSearchCV(\n",
    "    pipe,\n",
    "    params,\n",
    "    cv=4\n",
    ").fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_results(gs_bag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bagged tree still shows signs of overfitting. I will move on to a random forest model to control the overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('ss', StandardScaler()),\n",
    "    ('forest', RandomForestRegressor(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'forest__max_depth' : [10, 15, 20, 30],\n",
    "    'forest__min_samples_leaf' : [2, 3, 5],\n",
    "    'forest__max_features' : [4, 6, 10],\n",
    "    'forest__min_impurity_decrease' : [0.0, 0.1]\n",
    "}\n",
    "\n",
    "gs_forest = GridSearchCV(\n",
    "    pipe,\n",
    "    params,\n",
    "    cv=4\n",
    ").fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(gs_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Random Forest  + PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline to combine StandardScaler and KNN\n",
    "pipe = Pipeline(steps=[\n",
    "    ('ss', StandardScaler()),\n",
    "    ('pca', PCA()),\n",
    "    ('forest_pca', RandomForestRegressor(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'pca__n_components': [10, 15, 20],\n",
    "    'forest_pca__max_depth' : [10, 15, 20, 30],\n",
    "    'forest_pca__min_samples_leaf' : [2, 3, 5],\n",
    "    'forest_pca__max_features' : [5, 7, 10],\n",
    "    'forest_pca__min_impurity_decrease' : [0.0, 0.1]\n",
    "}\n",
    "\n",
    "gs_forest_pca = GridSearchCV(\n",
    "    pipe,\n",
    "    params,\n",
    "    cv=4\n",
    ").fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_results(gs_forest_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra Trees "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline to combine StandardScaler and KNN\n",
    "pipe = Pipeline(steps=[\n",
    "    ('ss', StandardScaler()),\n",
    "    ('extra', ExtraTreesRegressor(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'extra__max_depth' : [10, 15, 20, 30],\n",
    "    'extra__min_samples_leaf' : [2, 3, 5],\n",
    "    'extra__max_features' : [4, 6, 10],\n",
    "    'extra__min_impurity_decrease' : [0.0, 0.1]\n",
    "}\n",
    "\n",
    "gs_extra = GridSearchCV(\n",
    "    pipe,\n",
    "    params,\n",
    "    cv=4\n",
    ").fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(gs_extra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline to combine StandardScaler and KNN\n",
    "pipe = Pipeline(steps=[\n",
    "    ('ss', StandardScaler()),\n",
    "    ('ada', AdaBoostRegressor(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'ada__learning_rate' : [0.5, 1.0, 1.2],\n",
    "    'ada__loss' : ['linear', 'square', 'exponential']\n",
    "}\n",
    "\n",
    "gs_ada = GridSearchCV(\n",
    "    pipe,\n",
    "    params,\n",
    "    cv=4\n",
    ").fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(gs_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('sc', StandardScaler()),\n",
    "    ('svr', SVR())\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'svr__gamma' : ['scale'],\n",
    "    'svr__degree' : [2, 3, 4],\n",
    "    'svr__kernel' : ['linear', 'poly', 'rbf']\n",
    "}\n",
    "\n",
    "gs_svr = GridSearchCV(\n",
    "    pipe,\n",
    "    params,\n",
    "    cv=5\n",
    ").fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(gs_svr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('sc', StandardScaler()),\n",
    "    ('poly_features', PolynomialFeatures()),\n",
    "    ('lr', LinearRegression())\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'poly_features__degree': [1, 2, 3],\n",
    "}\n",
    "\n",
    "gs_poly = GridSearchCV(\n",
    "    pipe,\n",
    "    params,\n",
    "    cv=5\n",
    ").fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(gs_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('sc', StandardScaler()),\n",
    "    ('SGD', SGDRegressor())\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'SGD__max_iter': [800, 1000, 1200],\n",
    "    'SGD__penalty' : ['l1', 'l2'],\n",
    "    'SGD__tol': [1e-3]\n",
    "}\n",
    "\n",
    "gs_sgd = GridSearchCV(\n",
    "    pipe,\n",
    "    params,\n",
    "    cv=5\n",
    "    \n",
    ").fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(gs_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_all_test_score(model_list, grid_search=True, X_test=X_test, y_test=y_test):\n",
    "    if grid_search:\n",
    "        for model in model_list:\n",
    "            print(f'{model.estimator.steps[-1][0]} test score: {model.score(X_test, y_test)}')\n",
    "    else: \n",
    "         for model in model_list:\n",
    "            print(f'{type(model).__name__} test score: {model.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_grid_search_model_list = [dummy_mean, lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_model_list = [#lr_pca, gs_ridge, gs_lasso,\n",
    "                          gs_knn, \n",
    "                          gs_tree, gs_bag, gs_forest, \n",
    "                          gs_forest_pca, gs_extra, gs_ada,\n",
    "                          gs_svr, gs_poly, gs_sgd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_all_test_score(non_grid_search_model_list,  grid_search=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "view_all_test_score(grid_search_model_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best performing model is the bagged tree model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance(gs_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree plot\n",
    "gs_bag.best_estimator_.steps[1][1].estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "301.804px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
